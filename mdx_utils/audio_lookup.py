"""
Audio Lookup Module - éŸ³é¢‘å’ŒéŸ³è°ƒä¿¡æ¯æå–
ä»å¤šä¸ª MDX è¯å…¸ä¸­æå–éŸ³é¢‘å’ŒéŸ³è°ƒä¿¡æ¯

å¤ç”¨ mdxscraper.core.audio æ¨¡å—çš„åŠŸèƒ½
"""

from pathlib import Path
from typing import Optional, List, Tuple, Dict
from bs4 import BeautifulSoup
import re

from mdxscraper import Dictionary

# å¯¼å…¥ mdxscraper çš„éŸ³é¢‘å¤„ç†æ¨¡å—
try:
    from mdxscraper.core.audio import (
        AudioInfo,
        get_audio_info,
        extract_audio_paths_from_html,
        lookup_audio,
        embed_audio_in_html,
    )
    AUDIO_MODULE_AVAILABLE = True
except ImportError:
    AUDIO_MODULE_AVAILABLE = False
    AudioInfo = None

# å¯¼å…¥ fugashi ç”¨äºè·å–å®é™…è¯»éŸ³
try:
    import fugashi
    FUGASHI_AVAILABLE = True
except ImportError:
    FUGASHI_AVAILABLE = False


def extract_audio_from_mdx(mdx_file: Path, word: str, dict_name: str = None) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    """ä» MDX è¯å…¸ä¸­æå–éŸ³é¢‘ (ä½¿ç”¨ mdxscraper.core.audio)
    
    Args:
        mdx_file: MDX è¯å…¸æ–‡ä»¶è·¯å¾„
        word: è¦æŸ¥è¯¢çš„å•è¯
        dict_name: è¯å…¸åç§°
        
    Returns:
        (audio_base64, mime_type, source_dict) å…ƒç»„
        - audio_base64: base64 ç¼–ç çš„éŸ³é¢‘æ•°æ®
        - mime_type: éŸ³é¢‘ç±»å‹ (audio/aac, audio/mpeg, audio/wav ç­‰)
        - source_dict: æ¥æºè¯å…¸åç§°
    """
    if type(mdx_file) is not Path:
        mdx_file = Path(mdx_file)
    
    if dict_name is None:
        dict_name = mdx_file.stem
    
    if not AUDIO_MODULE_AVAILABLE:
        return None, None, None
    
    with Dictionary(mdx_file) as dict_obj:
        html_content = dict_obj.lookup_html(word)
        
        if not html_content:
            return None, None, None
        
        # ä½¿ç”¨ mdxscraper.core.audio.get_audio_info æå–éŸ³é¢‘
        try:
            audio_infos = get_audio_info(dict_obj.impl, word, html_content)
            
            if audio_infos and len(audio_infos) > 0:
                # è¿”å›ç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶
                first_audio = audio_infos[0]
                
                # AudioInfo åŒ…å« data_uri: "data:audio/mpeg;base64,..."
                # è§£æå‡º base64 æ•°æ®
                data_uri = first_audio.data_uri
                if data_uri.startswith('data:'):
                    match = re.match(r'data:([^;]+);base64,(.+)', data_uri)
                    if match:
                        mime_type, audio_base64 = match.groups()
                        return audio_base64, mime_type, dict_name
        
        except Exception:
            pass
        
        return None, None, None


def get_all_audio_info_from_mdx(mdx_file: Path, word: str, dict_name: str = None) -> List:
    """è·å–è¯æ¡çš„æ‰€æœ‰éŸ³é¢‘ä¿¡æ¯ (å¤ç”¨ mdxscraper.core.audio.get_audio_info)
    
    Args:
        mdx_file: MDX è¯å…¸æ–‡ä»¶è·¯å¾„
        word: è¦æŸ¥è¯¢çš„å•è¯
        dict_name: è¯å…¸åç§°
        
    Returns:
        AudioInfo åˆ—è¡¨,æ¯ä¸ªåŒ…å«:
        - word: è¯æ¡
        - audio_path: éŸ³é¢‘è·¯å¾„
        - audio_data: éŸ³é¢‘äºŒè¿›åˆ¶æ•°æ®
        - mime_type: MIME ç±»å‹
        - data_uri: base64 data URI
        - format: æ–‡ä»¶æ ¼å¼
    """
    if type(mdx_file) is not Path:
        mdx_file = Path(mdx_file)
    
    if dict_name is None:
        dict_name = mdx_file.stem
    
    if not AUDIO_MODULE_AVAILABLE:
        return []
    
    with Dictionary(mdx_file) as dict_obj:
        html_content = dict_obj.lookup_html(word)
        
        if not html_content:
            return []
        
        try:
            # ç›´æ¥è¿”å› mdxscraper çš„ AudioInfo åˆ—è¡¨
            audio_infos = get_audio_info(dict_obj.impl, word, html_content)
            return audio_infos
        
        except Exception:
            return []


def get_word_reading_with_fugashi(word: str) -> Optional[str]:
    """ä½¿ç”¨ fugashi è·å–å•è¯çš„è¯»éŸ³
    
    Args:
        word: æ—¥è¯­å•è¯
        
    Returns:
        è¯»éŸ³ (ç‰‡å‡å),å¦‚æœæ— æ³•è·å–åˆ™è¿”å› None
    """
    if not FUGASHI_AVAILABLE:
        return None
    
    try:
        tagger = fugashi.Tagger()
        result = tagger(word)
        
        if not result:
            return None
        
        # å–ç¬¬ä¸€ä¸ªè¯çš„è¯»éŸ³
        first_token = result[0]
        
        # å°è¯•å¤šç§æ–¹å¼è·å–è¯»éŸ³
        reading = None
        
        # æ–¹æ³•1: UniDic çš„ lForm å­—æ®µ (æœ€å‡†ç¡®çš„ç‰‡å‡åè¯»éŸ³)
        if hasattr(first_token.feature, 'lForm') and first_token.feature.lForm is not None:
            reading = first_token.feature.lForm
        
        # æ–¹æ³•2: UniDic çš„ kana å­—æ®µ (å¤‡é€‰)
        elif hasattr(first_token.feature, 'kana') and first_token.feature.kana is not None:
            reading = first_token.feature.kana
        
        # æ–¹æ³•3: ç›´æ¥è®¿é—® feature åˆ—è¡¨ (IPADic)
        # IPADic: [å“è©, å“è©ç´°åˆ†é¡1, å“è©ç´°åˆ†é¡2, å“è©ç´°åˆ†é¡3, æ´»ç”¨å‹, æ´»ç”¨å½¢, åŸå½¢, èª­ã¿, ç™ºéŸ³]
        elif hasattr(first_token, 'feature') and len(first_token.feature) > 7:
            reading = first_token.feature[7]  # è¯»éŸ³å­—æ®µ
        
        # æ–¹æ³•4: ä½¿ç”¨ features å±æ€§ (å¤‡é€‰)
        elif hasattr(first_token, 'features'):
            features = first_token.features
            if len(features) > 7:
                reading = features[7]
        
        # å¦‚æœè¯»éŸ³æ˜¯ "*" æˆ–ç©º,è¿”å› None
        if reading and reading != '*' and reading.strip():
            return reading
        
        return None
        
    except Exception as e:
        # è°ƒè¯•æ—¶å¯ä»¥æ‰“å°é”™è¯¯
        # print(f"Fugashi é”™è¯¯: {e}")
        return None


def normalize_reading(reading: str) -> str:
    """æ ‡å‡†åŒ–è¯»éŸ³æ ¼å¼ç”¨äºåŒ¹é…
    
    ç§»é™¤ HTML æ ‡ç­¾,è½¬æ¢ä¸ºç‰‡å‡å,ç»Ÿä¸€é•¿éŸ³ç¬¦å·
    
    Args:
        reading: è¯»éŸ³å­—ç¬¦ä¸² (å¯èƒ½åŒ…å« HTML)
        
    Returns:
        æ ‡å‡†åŒ–åçš„è¯»éŸ³
    """
    # ç§»é™¤ HTML æ ‡ç­¾
    plain = re.sub(r'<[^>]+>', '', reading)
    
    # ç»Ÿä¸€é•¿éŸ³ç¬¦å· (å…¨è§’)
    plain = plain.replace('ãƒ¼', 'ãƒ¼')
    
    # è½¬æ¢å¹³å‡ååˆ°ç‰‡å‡å (ç®€å•æ˜ å°„)
    hiragana_to_katakana = str.maketrans(
        'ãã‚ãƒã„ã…ã†ã‡ãˆã‰ãŠã‹ãŒããããã‘ã’ã“ã”ã•ã–ã—ã˜ã™ãšã›ãœãããŸã ã¡ã¢ã£ã¤ã¥ã¦ã§ã¨ã©ãªã«ã¬ã­ã®ã¯ã°ã±ã²ã³ã´ãµã¶ã·ã¸ã¹ãºã»ã¼ã½ã¾ã¿ã‚€ã‚ã‚‚ã‚ƒã‚„ã‚…ã‚†ã‚‡ã‚ˆã‚‰ã‚Šã‚‹ã‚Œã‚ã‚ã‚ã‚ã‚‘ã‚’ã‚“ã‚”ã‚•ã‚–',
        'ã‚¡ã‚¢ã‚£ã‚¤ã‚¥ã‚¦ã‚§ã‚¨ã‚©ã‚ªã‚«ã‚¬ã‚­ã‚®ã‚¯ã‚°ã‚±ã‚²ã‚³ã‚´ã‚µã‚¶ã‚·ã‚¸ã‚¹ã‚ºã‚»ã‚¼ã‚½ã‚¾ã‚¿ãƒ€ãƒãƒ‚ãƒƒãƒ„ãƒ…ãƒ†ãƒ‡ãƒˆãƒ‰ãƒŠãƒ‹ãƒŒãƒãƒãƒãƒãƒ‘ãƒ’ãƒ“ãƒ”ãƒ•ãƒ–ãƒ—ãƒ˜ãƒ™ãƒšãƒ›ãƒœãƒãƒãƒŸãƒ ãƒ¡ãƒ¢ãƒ£ãƒ¤ãƒ¥ãƒ¦ãƒ§ãƒ¨ãƒ©ãƒªãƒ«ãƒ¬ãƒ­ãƒ®ãƒ¯ãƒ°ãƒ±ãƒ²ãƒ³ãƒ´ãƒµãƒ¶'
    )
    plain = plain.translate(hiragana_to_katakana)
    
    return plain.upper()


def match_best_pitch(all_pitches: List[Tuple[str, str]], word: str) -> Tuple[str, str]:
    """ä»å¤šä¸ªéŸ³è°ƒé€‰é¡¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„
    
    ä½¿ç”¨ fugashi è·å–è¯è¯­çš„å®é™…è¯»éŸ³,ç„¶ååŒ¹é…æœ€æ¥è¿‘çš„éŸ³è°ƒä¿¡æ¯
    
    Args:
        all_pitches: æ‰€æœ‰éŸ³è°ƒä¿¡æ¯åˆ—è¡¨ [(reading_html, pitch_pos), ...]
        word: åŸå§‹å•è¯
        
    Returns:
        æœ€åŒ¹é…çš„ (reading_html, pitch_pos) å…ƒç»„
    """
    if not all_pitches:
        return (None, None)
    
    if len(all_pitches) == 1:
        return all_pitches[0]
    
    # å°è¯•ç”¨ fugashi è·å–å®é™…è¯»éŸ³
    actual_reading = get_word_reading_with_fugashi(word)
    
    if not actual_reading:
        # æ— æ³•è·å–å®é™…è¯»éŸ³,è¿”å›æœ€åä¸€ä¸ª (é€šå¸¸æ˜¯æœ€å¸¸ç”¨çš„)
        return all_pitches[-1]
    
    # æ ‡å‡†åŒ–å®é™…è¯»éŸ³
    normalized_actual = normalize_reading(actual_reading)
    
    # è®¡ç®—æ¯ä¸ªå€™é€‰è¯»éŸ³ä¸å®é™…è¯»éŸ³çš„ç›¸ä¼¼åº¦
    best_match = all_pitches[-1]  # é»˜è®¤æœ€åä¸€ä¸ª
    best_score = 0
    
    for reading_html, pitch_pos in all_pitches:
        normalized_candidate = normalize_reading(reading_html)
        
        # å®Œå…¨åŒ¹é…
        if normalized_candidate == normalized_actual:
            return (reading_html, pitch_pos)
        
        # è®¡ç®—ç›¸ä¼¼åº¦ (ç®€å•çš„å­—ç¬¦åŒ¹é…æ¯”ä¾‹)
        matches = sum(1 for a, b in zip(normalized_candidate, normalized_actual) if a == b)
        max_len = max(len(normalized_candidate), len(normalized_actual))
        score = matches / max_len if max_len > 0 else 0
        
        if score > best_score:
            best_score = score
            best_match = (reading_html, pitch_pos)
    
    return best_match


def extract_pitch_info_nhk_old(mdx_file: Path, word: str, return_all: bool = False) -> Tuple[Optional[str], Optional[str]] | List[Tuple[str, str]]:
    """ä»æ—§ç‰ˆ NHK æå–éŸ³è°ƒä¿¡æ¯ (å¸¦ Fugashi è¯»éŸ³éªŒè¯)
    
    æ—§ç‰ˆ NHK ä½¿ç”¨ tune-0/tune-1/tune-2 æ ‡è®°éŸ³é«˜:
    - tune-0: ä½éŸ³
    - tune-1: é«˜éŸ³ (æ·»åŠ ä¸Šåˆ’çº¿)
    - tune-2: ä¸‹é™éŸ³ (æ·»åŠ ä¸Šåˆ’çº¿,å¹¶è®°å½•ä¸‹é™ä½ç½®)
    
    âš ï¸  NHK è¯å…¸ç‰¹æ®Šæ ‡è®°å¤„ç†:
    - é¼»æµŠéŸ³æ ‡è®° (ã‚œ): å¦‚ ã‚«ã‚œã‚¯ (å®¶å…·çš„ç‰¹æ®Šè¯»éŸ³)
    - æ­¤å‡½æ•°ä¼šè‡ªåŠ¨ä½¿ç”¨ Fugashi çš„ lForm éªŒè¯è¯»éŸ³
    - å¦‚æœ NHK è¯»éŸ³ä¸ Fugashi ä¸ä¸€è‡´,è‡ªåŠ¨ä½¿ç”¨ Fugashi çš„æ ‡å‡†è¯»éŸ³
    - ä¿ç•™ NHK çš„éŸ³è°ƒä½ç½®ä¿¡æ¯
    
    Args:
        mdx_file: æ—§ç‰ˆ NHK MDX æ–‡ä»¶è·¯å¾„
        word: è¦æŸ¥è¯¢çš„å•è¯
        return_all: æ˜¯å¦è¿”å›æ‰€æœ‰è¯»éŸ³çš„éŸ³è°ƒä¿¡æ¯ (é»˜è®¤ False,åªè¿”å›ç¬¬ä¸€ä¸ª)
        
    Returns:
        å¦‚æœ return_all=False:
            (reading_with_marks, pitch_position) å…ƒç»„
        å¦‚æœ return_all=True:
            [(reading_with_marks, pitch_position), ...] åˆ—è¡¨
        
        - reading_with_marks: å¸¦ä¸Šåˆ’çº¿æ ‡è®°çš„å‡å (HTML) - å·²ä¿®æ­£ä¸ºæ ‡å‡†è¯»éŸ³
        - pitch_position: éŸ³è°ƒç±»å‹ [0], [1], [2] ç­‰
    
    Example:
        >>> # å®¶å…· - NHK: ã‚«ã‚œã‚¯ [1] (é¼»æµŠéŸ³) â†’ è‡ªåŠ¨ä¿®æ­£ä¸º: ã‚«ã‚° [1]
        >>> reading, pitch = extract_pitch_info_nhk_old(nhk_path, "å®¶å…·")
        >>> # reading: "ã‚«ã‚°" (æ ‡å‡†è¯»éŸ³), pitch: "[1]"
    """
    if type(mdx_file) is not Path:
        mdx_file = Path(mdx_file)
    
    with Dictionary(mdx_file) as dict_obj:
        html_content = dict_obj.lookup_html(word)
        
        if not html_content:
            return [] if return_all else (None, None)
        
        soup = BeautifulSoup(html_content, 'lxml')
        
        # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«éŸ³è°ƒä¿¡æ¯çš„å®¹å™¨ (å¯èƒ½æœ‰å¤šä¸ªè¯»éŸ³)
        # æ—§ç‰ˆ NHK å°†æ¯ä¸ªè¯»éŸ³æ”¾åœ¨å•ç‹¬çš„ <p> æ ‡ç­¾ä¸­
        # æ¯ä¸ª <p> æœ‰ä¸¤éƒ¨åˆ†: å‘éŸ³å›³ (å•è¯) å’Œ åŠ©è©ä»˜ (å¸¦åŠ©è¯),åªå–ç¬¬ä¸€éƒ¨åˆ†
        all_pitch_infos = []
        
        # ç­–ç•¥: æ‰¾åˆ°æ‰€æœ‰åŒ…å« tune-* ç±»çš„ <p> æ ‡ç­¾
        # æ¯ä¸ª <p> æ ‡ç­¾ä»£è¡¨ä¸€ä¸ªç‹¬ç«‹çš„è¯»éŸ³
        pitch_paragraphs = soup.find_all('p')
        
        for p_tag in pitch_paragraphs:
            # åœ¨è¿™ä¸ª <p> ä¸­æŸ¥æ‰¾æ‰€æœ‰ <a> æ ‡ç­¾ (éŸ³é¢‘é“¾æ¥)
            # é€šå¸¸æœ‰ä¸¤ä¸ª: ç™ºéŸ³å›³ å’Œ åŠ©è©ä»˜
            # æˆ‘ä»¬åªéœ€è¦ç¬¬ä¸€ä¸ª (ç™ºéŸ³å›³) åé¢çš„ tune å…ƒç´ 
            audio_links = p_tag.find_all('a', class_='aud-btn')
            
            if not audio_links:
                continue
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéŸ³é¢‘é“¾æ¥ (ç™ºéŸ³å›³) åé¢çš„ tune å…ƒç´ 
            # æ–¹æ³•: ä»ç¬¬ä¸€ä¸ª <a> æ ‡ç­¾å¼€å§‹,æ‰¾åˆ°ä¸‹ä¸€ä¸ª <br> æˆ–ç¬¬äºŒä¸ª <a> ä¹‹å‰çš„æ‰€æœ‰ tune-* å…ƒç´ 
            first_link = audio_links[0]
            
            # æ”¶é›†ç¬¬ä¸€ä¸ªéŸ³é¢‘é“¾æ¥åçš„ tune å…ƒç´ 
            reading_parts = []
            drop_position = 0
            current_pos = 0
            
            # éå†ç¬¬ä¸€ä¸ªé“¾æ¥ä¹‹åçš„å…„å¼ŸèŠ‚ç‚¹
            # åœ¨é‡åˆ° <br> ä¹‹å‰çš„æ‰€æœ‰ tune-* å…ƒç´ 
            for sibling in first_link.next_siblings:
                # å¦‚æœé‡åˆ° <br> æ ‡ç­¾,åœæ­¢ (ç¬¬ä¸€éƒ¨åˆ†ç»“æŸ)
                if hasattr(sibling, 'name') and sibling.name == 'br':
                    break
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ tune-* å…ƒç´ 
                if hasattr(sibling, 'get') and sibling.get('class'):
                    classes = sibling.get('class', [])
                    if any(c.startswith('tune-') for c in classes):
                        text = sibling.get_text()
                        
                        if 'tune-0' in classes:
                            reading_parts.append(text)
                        elif 'tune-1' in classes:
                            reading_parts.append(f'<span style="text-decoration: overline;">{text}</span>')
                        elif 'tune-2' in classes:
                            reading_parts.append(f'<span style="text-decoration: overline;">{text}</span>')
                            drop_position = current_pos + len(text)
                        
                        current_pos += len(text)
            
            if reading_parts:
                reading_html = ''.join(reading_parts)
                pitch_pos = f"[{drop_position}]"
                all_pitch_infos.append((reading_html, pitch_pos))
        
        # å»é‡ (å¯èƒ½æœ‰é‡å¤çš„)
        unique_infos = []
        seen_readings = set()
        for reading, pitch in all_pitch_infos:
            # ç§»é™¤ HTML æ ‡ç­¾ç”¨äºæ¯”è¾ƒ
            plain_reading = re.sub(r'<[^>]+>', '', reading)
            key = (plain_reading, pitch)
            if key not in seen_readings:
                seen_readings.add(key)
                unique_infos.append((reading, pitch))
        
        # ğŸ”§ æ–°å¢: ä½¿ç”¨ Fugashi éªŒè¯å’Œä¿®æ­£è¯»éŸ³ (å¤„ç† NHK é¼»æµŠéŸ³ç­‰ç‰¹æ®Šæ ‡è®°)
        if unique_infos and FUGASHI_AVAILABLE:
            verified_infos = []
            fugashi_reading = get_word_reading_with_fugashi(word)
            
            if fugashi_reading:
                # å°† Fugashi è¯»éŸ³è½¬æ¢ä¸ºå¹³å‡åç”¨äºæ¯”è¾ƒ
                try:
                    import jaconv
                    fugashi_hira = jaconv.kata2hira(fugashi_reading)
                except (ImportError, Exception):
                    # ç®€å•è½¬æ¢
                    fugashi_hira = fugashi_reading
                    for char in fugashi_reading:
                        code = ord(char)
                        if 0x30A1 <= code <= 0x30F6:
                            fugashi_hira = fugashi_hira.replace(char, chr(code - 0x60))
                
                for reading_html, pitch_pos in unique_infos:
                    # æå–çº¯æ–‡æœ¬è¯»éŸ³
                    plain_reading = re.sub(r'<[^>]+>', '', reading_html)
                    
                    # ç§»é™¤ NHK ç‰¹æ®Šæ ‡è®° (é¼»æµŠéŸ³ ã‚œã€é•¿éŸ³ ãƒ¼ ç­‰)
                    clean_reading = plain_reading.replace('ã‚œ', '').replace('â—Œã‚š', '')
                    
                    # è½¬æ¢ä¸ºå¹³å‡åç”¨äºæ¯”è¾ƒ
                    try:
                        import jaconv
                        clean_hira = jaconv.kata2hira(clean_reading)
                    except:
                        clean_hira = clean_reading
                        for char in clean_reading:
                            code = ord(char)
                            if 0x30A1 <= code <= 0x30F6:
                                clean_hira = clean_hira.replace(char, chr(code - 0x60))
                    
                    # æ¯”è¾ƒè¯»éŸ³
                    if clean_hira != fugashi_hira:
                        # è¯»éŸ³ä¸åŒ¹é… (å¦‚ NHK çš„é¼»æµŠéŸ³ ã‚«ã‚œã‚¯ vs Fugashi çš„ ã‚«ã‚°)
                        # ä½¿ç”¨ Fugashi çš„è¯»éŸ³ï¼Œä¿ç•™ NHK çš„éŸ³è°ƒä½ç½®
                        
                        # å°† Fugashi è¯»éŸ³è½¬æ¢ä¸ºç‰‡å‡å
                        fugashi_kata = fugashi_reading
                        
                        # æ ¹æ®éŸ³è°ƒä½ç½®é‡å»º HTML
                        # æå–éŸ³è°ƒä½ç½®æ•°å­—
                        pitch_num = 0
                        pitch_match = re.search(r'\[(\d+)\]', pitch_pos)
                        if pitch_match:
                            pitch_num = int(pitch_match.group(1))
                        
                        # é‡å»ºå¸¦éŸ³è°ƒæ ‡è®°çš„ HTML
                        new_reading_parts = []
                        for i, char in enumerate(fugashi_kata):
                            pos = i + 1
                            
                            if pitch_num == 0:
                                # å¹³æ¿å¼: ç¬¬ä¸€æ‹æ— çº¿,ç¬¬äºŒæ‹å¼€å§‹æœ‰ä¸Šåˆ’çº¿
                                if pos > 1:
                                    new_reading_parts.append(f'<span style="text-decoration: overline;">{char}</span>')
                                else:
                                    new_reading_parts.append(char)
                            elif pitch_num == 1:
                                # é ­é«˜å‹: ç¬¬ä¸€æ‹æœ‰ä¸Šåˆ’çº¿,åç»­æ— çº¿
                                if pos == 1:
                                    new_reading_parts.append(f'<span style="text-decoration: overline;">{char}</span>')
                                else:
                                    new_reading_parts.append(char)
                            else:
                                # ä¸­é«˜å‹/å°¾é«˜å‹: ç¬¬äºŒæ‹åˆ°ä¸‹é™ä½ç½®æœ‰ä¸Šåˆ’çº¿
                                if 2 <= pos <= pitch_num:
                                    new_reading_parts.append(f'<span style="text-decoration: overline;">{char}</span>')
                                else:
                                    new_reading_parts.append(char)
                        
                        corrected_reading_html = ''.join(new_reading_parts)
                        verified_infos.append((corrected_reading_html, pitch_pos))
                        
                        # å¯é€‰: æ‰“å°è­¦å‘Š (è°ƒè¯•æ—¶ä½¿ç”¨)
                        # print(f"âš ï¸  NHK è¯»éŸ³ä¿®æ­£: {word} - NHK:{plain_reading} â†’ Fugashi:{fugashi_kata}")
                    else:
                        # è¯»éŸ³ä¸€è‡´,ä¿ç•™åŸæ ·
                        verified_infos.append((reading_html, pitch_pos))
                
                unique_infos = verified_infos if verified_infos else unique_infos
        
        if return_all:
            return unique_infos
        else:
            # ä½¿ç”¨ fugashi æ™ºèƒ½åŒ¹é…æœ€åˆé€‚çš„è¯»éŸ³
            return match_best_pitch(unique_infos, word)


class AudioLookup:
    """éŸ³é¢‘å’ŒéŸ³è°ƒä¿¡æ¯æŸ¥è¯¢ç±»
    
    æŒ‰ä¼˜å…ˆçº§ä»å¤šä¸ªè¯å…¸ä¸­æå–éŸ³é¢‘å’ŒéŸ³è°ƒä¿¡æ¯:
    1. æ–°ç‰ˆ NHK (AAC éŸ³é¢‘,éŸ³è°ƒæ ‡è®°ä¸å®Œæ•´)
    2. æ—§ç‰ˆ NHK (å®Œæ•´éŸ³è°ƒæ ‡è®°)
    3. å¤§è¾æ³‰ ç¬¬äºŒç‰ˆ (æœ‰éŸ³é¢‘å’Œä¸‹é™ä½ç½®æ ‡è®°)
    
    Attributes:
        audio_dicts: éŸ³é¢‘è¯å…¸åˆ—è¡¨ [(Path, æ˜¾ç¤ºåç§°)]
        pitch_dict: éŸ³è°ƒè¯å…¸è·¯å¾„ (æ—§ç‰ˆ NHK)
        
    Example:
        >>> audio_lookup = AudioLookup(
        ...     audio_dicts=[
        ...         (Path("nhk_new.mdx"), "NHKæ–°ç‰ˆ"),
        ...         (Path("nhk_old.mdx"), "NHKæ—§ç‰ˆ"),
        ...         (Path("djs.mdx"), "å¤§è¾æ³‰"),
        ...     ],
        ...     pitch_dict=Path("nhk_old.mdx")
        ... )
        >>> 
        >>> result = audio_lookup.lookup("æ”¿æ¨©")
        >>> print(result['audio_source'])  # "NHKæ–°ç‰ˆ"
        >>> print(result['pitch_position'])  # "[2]"
    """
    
    def __init__(
        self,
        audio_dicts: List[Tuple[Path, str]],
        pitch_dict: Optional[Path] = None
    ):
        """åˆå§‹åŒ–éŸ³é¢‘æŸ¥è¯¢å™¨
        
        Args:
            audio_dicts: [(mdx_path, æ˜¾ç¤ºåç§°), ...] æŒ‰ä¼˜å…ˆçº§æ’åˆ—
            pitch_dict: éŸ³è°ƒè¯å…¸è·¯å¾„ (é€šå¸¸æ˜¯æ—§ç‰ˆ NHK)
        """
        self.audio_dicts = audio_dicts
        self.pitch_dict = pitch_dict
    
    @classmethod
    def from_dirs(
        cls,
        nhk_new_dir: Optional[Path] = None,
        nhk_old_dir: Optional[Path] = None,
        djs_dir: Optional[Path] = None,
        dict_names: Optional[Dict[str, str]] = None
    ) -> "AudioLookup":
        """ä»ç›®å½•åˆå§‹åŒ–éŸ³é¢‘æŸ¥è¯¢å™¨
        
        Args:
            nhk_new_dir: æ–°ç‰ˆ NHK ç›®å½• (æˆ– .mdx æ–‡ä»¶)
            nhk_old_dir: æ—§ç‰ˆ NHK ç›®å½• (æˆ– .mdx æ–‡ä»¶)
            djs_dir: å¤§è¾æ³‰ç›®å½• (æˆ– .mdx æ–‡ä»¶)
            dict_names: {æ–‡ä»¶å: æ˜¾ç¤ºåç§°} æ˜ å°„
            
        Returns:
            AudioLookup å®ä¾‹
        """
        audio_dicts = []
        pitch_dict = None
        
        dict_names = dict_names or {}
        
        # æ–°ç‰ˆ NHK
        if nhk_new_dir:
            nhk_new_path = Path(nhk_new_dir)
            if nhk_new_path.is_file():
                mdx_file = nhk_new_path
            else:
                mdx_files = list(nhk_new_path.glob("*.mdx"))
                mdx_file = mdx_files[0] if mdx_files else None
            
            if mdx_file and mdx_file.exists():
                display_name = dict_names.get(mdx_file.name, "NHKæ–°ç‰ˆ")
                audio_dicts.append((mdx_file, display_name))
        
        # æ—§ç‰ˆ NHK
        if nhk_old_dir:
            nhk_old_path = Path(nhk_old_dir)
            if nhk_old_path.is_file():
                mdx_file = nhk_old_path
            else:
                mdx_files = list(nhk_old_path.glob("*.mdx"))
                mdx_file = mdx_files[0] if mdx_files else None
            
            if mdx_file and mdx_file.exists():
                display_name = dict_names.get(mdx_file.name, "NHKæ—§ç‰ˆ")
                audio_dicts.append((mdx_file, display_name))
                pitch_dict = mdx_file  # ç”¨äºéŸ³è°ƒæå–
        
        # å¤§è¾æ³‰
        if djs_dir:
            djs_path = Path(djs_dir)
            if djs_path.is_file():
                mdx_file = djs_path
            else:
                mdx_files = list(djs_path.glob("*.mdx"))
                mdx_file = mdx_files[0] if mdx_files else None
            
            if mdx_file and mdx_file.exists():
                display_name = dict_names.get(mdx_file.name, "å¤§è¾æ³‰")
                audio_dicts.append((mdx_file, display_name))
        
        return cls(audio_dicts, pitch_dict)
    
    def lookup(self, word: str, verbose: bool = False, return_all_pitches: bool = False) -> Dict:
        """æŸ¥è¯¢å•è¯çš„éŸ³é¢‘å’ŒéŸ³è°ƒä¿¡æ¯
        
        Args:
            word: è¦æŸ¥è¯¢çš„å•è¯
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            return_all_pitches: æ˜¯å¦è¿”å›æ‰€æœ‰å¯èƒ½çš„éŸ³è°ƒä¿¡æ¯ (é»˜è®¤ False,åªè¿”å›ç¬¬ä¸€ä¸ª)
            
        Returns:
            {
                'audio_base64': str,  # base64 éŸ³é¢‘æ•°æ®
                'audio_mime': str,    # éŸ³é¢‘ç±»å‹
                'audio_source': str,  # æ¥æºè¯å…¸
                'reading': str,       # å¸¦æ ‡è®°çš„å‡åè¯»éŸ³(HTML) - ç¬¬ä¸€ä¸ª
                'pitch_position': str,# éŸ³è°ƒç±»å‹ [0], [1] ç­‰ - ç¬¬ä¸€ä¸ª
                'pitch_source': str,  # éŸ³è°ƒæ¥æº
                'all_pitches': list,  # æ‰€æœ‰éŸ³è°ƒä¿¡æ¯ [(reading, position), ...] (ä»…å½“ return_all_pitches=True)
            }
        """
        result = {
            'audio_base64': None,
            'audio_mime': None,
            'audio_source': None,
            'reading': None,
            'pitch_position': None,
            'pitch_source': None,
        }
        
        if return_all_pitches:
            result['all_pitches'] = []
        
        # 1. æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾éŸ³é¢‘
        for mdx_path, dict_name in self.audio_dicts:
            audio_data, mime_type, source = extract_audio_from_mdx(mdx_path, word, dict_name)
            if audio_data:
                result['audio_base64'] = audio_data
                result['audio_mime'] = mime_type
                result['audio_source'] = source
                if verbose:
                    print(f"âœ… éŸ³é¢‘: {source} ({mime_type})")
                break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå°±åœæ­¢
        
        # 2. ä»éŸ³è°ƒè¯å…¸æå–éŸ³è°ƒä¿¡æ¯
        if self.pitch_dict and self.pitch_dict.exists():
            if return_all_pitches:
                # è·å–æ‰€æœ‰éŸ³è°ƒä¿¡æ¯
                all_pitch_infos = extract_pitch_info_nhk_old(self.pitch_dict, word, return_all=True)
                
                if all_pitch_infos:
                    result['all_pitches'] = all_pitch_infos
                    # ç¬¬ä¸€ä¸ªä½œä¸ºé»˜è®¤å€¼
                    result['reading'] = all_pitch_infos[0][0]
                    result['pitch_position'] = all_pitch_infos[0][1]
                    result['pitch_source'] = 'NHKæ—§ç‰ˆ'
                    
                    if verbose:
                        print(f"âœ… éŸ³è°ƒ: NHKæ—§ç‰ˆ æ‰¾åˆ° {len(all_pitch_infos)} ä¸ªè¯»éŸ³")
                        for i, (reading, pitch) in enumerate(all_pitch_infos, 1):
                            # ç§»é™¤ HTML æ ‡ç­¾ç”¨äºæ˜¾ç¤º
                            plain_reading = re.sub(r'<[^>]+>', '', reading)
                            print(f"   {i}. {plain_reading} {pitch}")
            else:
                # åªè·å–ç¬¬ä¸€ä¸ªéŸ³è°ƒä¿¡æ¯
                reading, pitch_pos = extract_pitch_info_nhk_old(self.pitch_dict, word, return_all=False)
                if reading:
                    result['reading'] = reading
                    result['pitch_position'] = pitch_pos
                    result['pitch_source'] = 'NHKæ—§ç‰ˆ'
                    if verbose:
                        print(f"âœ… éŸ³è°ƒ: NHKæ—§ç‰ˆ {pitch_pos}")
        
        return result
    
    def format_for_anki(self, result: Dict) -> Dict:
        """å°†æŸ¥è¯¢ç»“æœæ ¼å¼åŒ–ä¸º Anki å­—æ®µ
        
        Args:
            result: lookup() çš„è¿”å›å€¼
            
        Returns:
            {
                'audio': dict,  # {'data': base64, 'filename': str}
                'reading': str,  # å¸¦æ ‡è®°çš„å‡å
                'pitchPosition': str,  # [0], [1] ç­‰
            }
        """
        anki_fields = {
            'audio': None,
            'reading': result.get('reading', ''),
            'pitchPosition': result.get('pitch_position', ''),
        }
        
        # éŸ³é¢‘å­—æ®µ
        if result.get('audio_base64'):
            # æ‰©å±•åæ ¹æ® MIME ç±»å‹ç¡®å®š
            mime_to_ext = {
                'audio/mpeg': 'mp3',
                'audio/aac': 'aac',
                'audio/wav': 'wav',
                'audio/ogg': 'ogg',
            }
            ext = mime_to_ext.get(result['audio_mime'], 'mp3')
            
            # AnkiConnect éŸ³é¢‘æ ¼å¼
            anki_fields['audio'] = {
                'data': result['audio_base64'],
                'filename': f"audio_{hash(result['audio_base64'][:100])}.{ext}",
                'fields': ['audio']  # è¦æ·»åŠ åˆ°çš„å­—æ®µå
            }
        
        return anki_fields
